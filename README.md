# üöÄ AI-Powered Research Quality Application - Developer Guide

A comprehensive Flask-based web application for investment research analysis, quality assessment, and AI-powered insights with real-time market data integration.

## üìã Table of Contents

- [üéØ Overview](#-overview)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üõ†Ô∏è Tech Stack](#Ô∏è-tech-stack)
- [üìä Features](#-features)
- [üóÑÔ∏è Database Schema](#Ô∏è-database-schema)****
- [üì° API Endpoints](#-api-endpoints)
- [üß† AI & ML Components](#-ai--ml-components)
- [üöÄ Installation & Setup](#-installation--setup)
- [üîß Configuration](#-configuration)
- [üìÅ Project Structure](#-project-structure)
- [ÔøΩÔ∏è Core Modules](#Ô∏è-core-modules)
- [üîå External Integrations](#-external-integrations)
- [üß™ Testing](#-testing)
- [üìö Usage Examples](#-usage-examples)
- [ü§ñ Agentic AI System](#-agentic-ai-system)
- [üõ°Ô∏è Security Features](#Ô∏è-security-features)
- [üìà Performance & Monitoring](#-performance--monitoring)
- [üöÄ Deployment](#-deployment)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)

## üéØ Overview

This application is a sophisticated **Investment Research Quality Assessment Platform** that combines:

- **AI-Powered Analysis**: Advanced NLP and machine learning for report analysis
- **Real-time Market Data**: Live stock prices and market insights via Yahoo Finance
- **Quality Scoring**: Automated scoring of research reports using multiple metrics
- **Plagiarism Detection**: BERT-based similarity detection for content integrity
- **AI Detection**: Identification of AI-generated content in research reports
- **Agentic AI System**: Autonomous AI agents for investment recommendations
- **Knowledge Base**: Intelligent storage and retrieval of research insights
- **RESTful APIs**: Comprehensive API layer for all functionalities

### üéØ Target Users
- **Investment Analysts**: Research creation and quality assessment
- **Portfolio Managers**: Investment insights and recommendations
- **Research Directors**: Team performance monitoring and quality control
- **Investors**: AI-powered investment guidance and market analysis
- **Developers**: API access for custom integrations

## ÔøΩÔ∏è Architecture

```mermaid
graph TB
    A[Web Interface] --> B[Flask Application]
    B --> C[Authentication Layer]
    C --> D[Core Modules]
    
    D --> E[Report Analysis Engine]
    D --> F[AI Research Assistant]
    D --> G[Agentic AI System]
    D --> H[Quality Assessment]
    
    E --> I[NLP Processing]
    E --> J[Plagiarism Detection]
    E --> K[AI Detection]
    
    F --> L[Knowledge Base]
    F --> M[Claude API]
    
    G --> N[Investment Agents]
    G --> O[Recommendation Engine]
    
    H --> P[Quality Scoring]
    H --> Q[Performance Metrics]
    
    R[External APIs] --> S[Yahoo Finance]
## üõ†Ô∏è Tech Stack

### Backend
- **Framework**: Flask 2.3+
- **Database**: SQLAlchemy ORM with SQLite (dev) / PostgreSQL (prod)
- **Real-time**: Flask-SocketIO for live updates
- **Authentication**: Flask session-based auth
- **API**: RESTful endpoints with JSON responses

### AI & Machine Learning
- **NLP**: Transformers library with BERT models
- **LLM Integration**: Anthropic Claude Sonnet for advanced analysis
- **Market Data**: Yahoo Finance API (yfinance)
- **Text Processing**: spaCy, NLTK
- **Similarity Detection**: Cosine similarity, TF-IDF vectors

### Frontend
- **Templates**: Jinja2 templating engine
- **Styling**: Bootstrap 5.3, Custom CSS
- **JavaScript**: Vanilla JS, Chart.js for visualizations
- **Real-time Updates**: Socket.IO client

### Infrastructure
- **Web Server**: Gunicorn (production)
- **Process Management**: systemd / PM2
- **Monitoring**: Custom logging and metrics
- **File Storage**: Local filesystem

## üìä Features

### üîç Core Analysis Features
- **Report Quality Assessment**: Multi-dimensional scoring algorithm
- **Plagiarism Detection**: BERT-based semantic similarity analysis
- **AI Content Detection**: Machine learning models to identify AI-generated text
- **Ticker Extraction**: Automated extraction of stock symbols from text
- **Sentiment Analysis**: Market sentiment evaluation
- **Financial Metrics Extraction**: Key financial data parsing

### ü§ñ AI-Powered Features
- **AI Research Assistant**: Context-aware query processing
- **Knowledge Base Integration**: Intelligent information retrieval
- **Automated Report Generation**: AI-assisted research creation
- **Real-time Market Analysis**: Live market data integration
- **Investment Recommendations**: AI-driven stock suggestions

### üë• User Management
- **Multi-role Support**: Analysts, Investors, Admins
- **Performance Tracking**: Individual analyst metrics
- **Dashboard Customization**: Role-based interface adaptation
- **Activity Monitoring**: Comprehensive audit trails

### üìà Analytics & Reporting
- **Performance Dashboards**: Real-time metrics visualization
- **Comparative Analysis**: Report comparison tools
- **Historical Trends**: Time-series analysis of quality metrics
- **Export Capabilities**: PDF, Excel, JSON export options

## üóÑÔ∏è Database Schema

### Core Models

#### Report Model
```python
class Report(db.Model):
    id = db.Column(db.String(32), primary_key=True)
    analyst = db.Column(db.String(100))
    original_text = db.Column(db.Text)
    analysis_result = db.Column(db.Text)  # JSON
    tickers = db.Column(db.Text)  # Comma-separated
    created_at = db.Column(db.DateTime)
    
    # Quality Assessment
    plagiarism_score = db.Column(db.Float)
    ai_probability = db.Column(db.Float)
    ai_confidence = db.Column(db.Float)
    
    # AI Analysis
    ai_classification = db.Column(db.String(100))
    ai_analysis_result = db.Column(db.Text)  # JSON
```

#### User Models
```python
class InvestorAccount(db.Model):
    id = db.Column(db.String(32), primary_key=True)
    name = db.Column(db.String(100))
    email = db.Column(db.String(100))
    investment_profile = db.Column(db.Text)  # JSON
    risk_tolerance = db.Column(db.String(20))
    created_at = db.Column(db.DateTime)

class InvestorQuery(db.Model):
    id = db.Column(db.String(32), primary_key=True)
    investor_id = db.Column(db.String(32))
    query_text = db.Column(db.Text)
    query_type = db.Column(db.String(50))
    ai_response = db.Column(db.Text)
    created_at = db.Column(db.DateTime)
```

#### Knowledge Base
```python
class KnowledgeBase(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    content_type = db.Column(db.String(50))
    title = db.Column(db.String(200))
    content = db.Column(db.Text)
    summary = db.Column(db.Text)
    keywords = db.Column(db.Text)  # JSON array
    meta_data = db.Column(db.Text)  # JSON
```

#### Agentic AI Models
```python
class InvestmentAgent(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    agent_name = db.Column(db.String(100))
    investor_id = db.Column(db.String(32))
    total_recommendations = db.Column(db.Integer)
    successful_recommendations = db.Column(db.Integer)
    accuracy_rate = db.Column(db.Float)
    total_return = db.Column(db.Float)

class AgentRecommendation(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    agent_id = db.Column(db.Integer)
    ticker = db.Column(db.String(20))
    recommendation_type = db.Column(db.String(20))  # BUY, SELL, HOLD
    confidence_score = db.Column(db.Float)
    target_price = db.Column(db.Float)
    reasoning = db.Column(db.Text)
```

## üì° API Endpoints

### üîç Core APIs

#### Main Dashboard API
```
GET /api/main_dashboard
Returns comprehensive dashboard data including recent reports, analytics, and market overview.

Response:
{
  "success": true,
  "recent_reports": [...],
  "analytics": {...},
  "market_overview": {...}
}
```

#### Report Analysis API
```
GET /api/enhanced_analysis_reports?limit=10&ticker=INFY.NS
Returns paginated list of enhanced analysis reports with filtering options.

Parameters:
- limit: Number of reports to return (default: 10)
- ticker: Filter by stock ticker
- analyst: Filter by analyst name
- date_from: Start date filter
```

#### AI Research Assistant API
```
POST /api/ai_research_assistant
Process investor queries using AI-powered analysis.

Request Body:
{
  "query": "What are the latest insights on INFY stock?",
  "investor_id": "optional_investor_id"
}

Response:
{
  "success": true,
  "ai_response": "Detailed AI-generated response...",
  "confidence_score": 0.85,
  "sources": [...]
}
```

### üìä Analytics APIs

#### Performance Analytics
```
GET /api/admin/performance?days=30
Get comprehensive performance analytics for specified time period.

Parameters:
- days: Time period in days (default: 30)
- analyst: Filter by specific analyst
- metric: Specific metric to focus on
```

#### Analyst Performance
```
GET /api/analyst/{name}/performance
Get detailed performance metrics for a specific analyst.

Response includes:
- Report count and quality scores
- Improvement trends
- Comparative rankings
- Recent performance history
```

### ü§ñ Agentic AI APIs

#### Agent Recommendations
```
GET /api/agentic/recommendations
Get AI agent investment recommendations.

Response:
{
  "status": "success",
  "data": [
    {
      "ticker": "RELIANCE.NS",
      "recommendation_type": "STRONG_BUY",
      "confidence_score": 0.92,
      "target_price": 2950.0,
      "reasoning": "Strong Q3 results..."
    }
  ]
}
```

#### Portfolio Analysis
```
GET /api/agentic/portfolio_analysis
Get AI-powered portfolio analysis and insights.
```

### üìà Real-time Data APIs

#### Market Metrics
```
GET /api/metrics
Get real-time market metrics and system statistics.

Response includes:
- Live stock prices
- Market indices
- System performance metrics
- User activity statistics
```

## üß† AI & ML Components

### 1. Quality Scoring Engine

The application uses a sophisticated multi-dimensional scoring system:

```python
def calculate_quality_score(report_text, analysis_result):
    """
    Comprehensive quality assessment combining:
    - Content depth analysis
    - Technical analysis accuracy
    - Data source reliability
    - Writing quality metrics
    - Timeliness factors
    """
    scores = {
        'content_depth': analyze_content_depth(report_text),
        'technical_accuracy': assess_technical_accuracy(analysis_result),
        'data_reliability': check_data_sources(report_text),
        'writing_quality': evaluate_writing_quality(report_text),
        'timeliness': assess_timeliness(report_text)
    }
    
    return weighted_average(scores, weights={
        'content_depth': 0.3,
        'technical_accuracy': 0.25,
        'data_reliability': 0.2,
        'writing_quality': 0.15,
        'timeliness': 0.1
    })
```

### 2. Plagiarism Detection System

BERT-based semantic similarity detection:

```python
class PlagiarismDetector:
    def __init__(self):
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        self.model = BertModel.from_pretrained('bert-base-uncased')
    
    def detect_similarity(self, text1, text2):
        """
        Calculate semantic similarity between two texts
        Returns similarity score (0-1) and matched segments
        """
        embeddings1 = self.get_embeddings(text1)
        embeddings2 = self.get_embeddings(text2)
        
        similarity = cosine_similarity(embeddings1, embeddings2)
        return self.process_similarity_results(similarity)
```

### 3. AI Content Detection

Machine learning model to identify AI-generated content:

```python
def detect_ai_content(text):
    """
    Multi-model approach to detect AI-generated content:
    - Statistical analysis of writing patterns
    - Vocabulary complexity assessment
    - Sentence structure analysis
    - Coherence pattern recognition
    """
    features = extract_linguistic_features(text)
    probability = ai_detection_model.predict(features)
    
    return {
        'ai_probability': probability,
        'confidence': calculate_confidence(features),
        'indicators': identify_ai_indicators(text)
    }
```

### 4. Knowledge Base Intelligence

Semantic search and content retrieval:

```python
class IntelligentKnowledgeBase:
    def search(self, query, context=None):
        """
        Advanced search combining:
        - Semantic similarity matching
        - Contextual relevance scoring
        - Historical query learning
        - Multi-source content fusion
        """
        extracted_data = self.extract_query_components(query)
        relevant_content = self.semantic_search(extracted_data)
        return self.rank_and_synthesize(relevant_content, query)
```

## üöÄ Installation & Setup

### Prerequisites

```bash
# Python 3.8+ required
python --version

# Required system packages (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install python3-dev python3-pip postgresql postgresql-dev
```

### Step 1: Clone Repository

```bash
git clone <repository-url>
cd research-quality-app
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
# Install Python packages
pip install -r requirements.txt

# Download required NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Download spaCy model
python -m spacy download en_core_web_sm
```

### Step 4: Environment Configuration

Create `.env` file in root directory:

```bash
# Database Configuration
DATABASE_URL=sqlite:///instance/reports.db
# For PostgreSQL: postgresql://username:password@localhost/dbname

# API Keys
ANTHROPIC_API_KEY=your_claude_api_key_here
YAHOO_FINANCE_API_KEY=optional_key_here

# Application Settings
SECRET_KEY=your-secret-key-here
DEBUG=True
FLASK_ENV=development

# AI Model Settings
BERT_MODEL_PATH=bert-base-uncased
AI_DETECTION_THRESHOLD=0.7
PLAGIARISM_THRESHOLD=0.8

# External Service URLs
CLAUDE_API_URL=https://api.anthropic.com
MARKET_DATA_SOURCE=yahoo_finance
```

### Step 5: Database Setup

```bash
# Initialize database
python -c "
from app import app, db
with app.app_context():
    db.create_all()
    print('Database initialized successfully')
"

# Optional: Load sample data
python load_sample_data.py
```

### Step 6: Verify Installation

```bash
# Run syntax check
python -c "import app; print('‚úÖ All imports successful')"

# Start development server
python app.py
```

Navigate to `http://localhost:5008` to access the application.

## üîß Configuration

### Application Settings

The application uses a configuration class system:

```python
class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'
    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL')
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # AI Model Configuration
    ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')
    AI_DETECTION_THRESHOLD = float(os.environ.get('AI_DETECTION_THRESHOLD', 0.7))
    PLAGIARISM_THRESHOLD = float(os.environ.get('PLAGIARISM_THRESHOLD', 0.8))
    
    # Performance Settings
    MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB max file size
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_timeout': 20,
        'pool_recycle': -1,
        'pool_pre_ping': True
    }
```

### Feature Toggles

Enable/disable features via environment variables:

```bash
# AI Features
ENABLE_AI_DETECTION=True
ENABLE_PLAGIARISM_CHECK=True
ENABLE_CLAUDE_INTEGRATION=True

# External APIs
ENABLE_REAL_TIME_DATA=True
ENABLE_MARKET_ANALYSIS=True

# Performance Features
ENABLE_CACHING=True
ENABLE_BACKGROUND_TASKS=True
```

## üìÅ Project Structure

```
research-quality-app/
‚îú‚îÄ‚îÄ app.py                          # Main Flask application
‚îú‚îÄ‚îÄ config.py                       # Configuration management
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ README.md                       # This file
‚îÇ
‚îú‚îÄ‚îÄ instance/                       # Instance-specific files
‚îÇ   ‚îî‚îÄ‚îÄ reports.db                  # SQLite database (dev)
‚îÇ
‚îú‚îÄ‚îÄ templates/                      # Jinja2 templates
‚îÇ   ‚îú‚îÄ‚îÄ index.html                  # Main dashboard
‚îÇ   ‚îú‚îÄ‚îÄ investor_dashboard.html     # Investor interface
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_analysis.html      # Analysis reports view
‚îÇ   ‚îú‚îÄ‚îÄ admin_dashboard.html        # Admin interface
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_ai_research_assistant.html  # AI assistant
‚îÇ   ‚îú‚îÄ‚îÄ agentic_dashboard.html      # Agentic AI interface
‚îÇ   ‚îî‚îÄ‚îÄ compare_reports.html        # Report comparison
‚îÇ
‚îú‚îÄ‚îÄ models/                         # AI/ML model components
‚îÇ   ‚îú‚îÄ‚îÄ ai_detection.py            # AI content detection
‚îÇ   ‚îú‚îÄ‚îÄ llm_integration.py         # LLM integration layer
‚îÇ   ‚îî‚îÄ‚îÄ scoring.py                 # Quality scoring algorithms
‚îÇ
‚îú‚îÄ‚îÄ static/                         # Static assets
‚îÇ   ‚îú‚îÄ‚îÄ css/                       # Custom stylesheets
‚îÇ   ‚îú‚îÄ‚îÄ js/                        # JavaScript files
‚îÇ   ‚îî‚îÄ‚îÄ images/                    # Image assets
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py                # API endpoint tests
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py             # Model tests
‚îÇ   ‚îî‚îÄ‚îÄ test_ai_features.py        # AI functionality tests
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ api_documentation.md       # API reference
‚îÇ   ‚îú‚îÄ‚îÄ deployment_guide.md        # Deployment instructions
‚îÇ   ‚îî‚îÄ‚îÄ user_manual.md            # User documentation
‚îÇ
‚îî‚îÄ‚îÄ scripts/                       # Utility scripts
    ‚îú‚îÄ‚îÄ load_sample_data.py        # Sample data loader
    ‚îú‚îÄ‚îÄ migrate_database.py        # Database migration
    ‚îî‚îÄ‚îÄ performance_monitor.py     # Performance monitoring
```

## üéõÔ∏è Core Modules

### 1. Report Analysis Engine (`app.py` lines 1-2000)

Handles the core functionality of analyzing investment research reports:

```python
@app.route('/analyze', methods=['POST'])
def analyze_report():
    """
    Main report analysis endpoint that orchestrates:
    1. Text preprocessing and cleaning
    2. Ticker extraction from content
    3. Quality score calculation
    4. AI content detection
    5. Plagiarism checking
    6. Result storage and indexing
    """
```

**Key Functions:**
- `extract_tickers_from_text()`: Intelligent ticker symbol extraction
- `calculate_quality_score()`: Multi-dimensional quality assessment
- `detect_ai_content()`: Machine learning-based AI detection
- `check_plagiarism()`: BERT-based similarity analysis

### 2. AI Research Assistant (`app.py` lines 2000-4000)

Provides intelligent query processing and knowledge retrieval:

```python
@app.route('/ai_research_assistant')
def ai_research_assistant():
    """
    Advanced AI-powered research assistant featuring:
    - Natural language query understanding
    - Knowledge base search and synthesis
    - Real-time market data integration
    - Contextual response generation
    """
```

**Key Components:**
- Query analysis and intent recognition
- Knowledge base semantic search
- Multi-source content synthesis
- Response confidence scoring

### 3. Agentic AI System (`app.py` lines 8000-11000)

Autonomous AI agents for investment management:

```python
class InvestmentAgent:
    """
    Autonomous AI agents capable of:
    - Portfolio monitoring and analysis
    - Investment recommendation generation
    - Risk assessment and alerts
    - Performance tracking and optimization
    """
```

**Agent Capabilities:**
- Real-time portfolio monitoring
- Automated rebalancing suggestions
- Risk-adjusted performance optimization
- Market sentiment analysis integration

### 4. Quality Assessment Framework

Multi-layered approach to research quality evaluation:

```python
def comprehensive_quality_assessment(report):
    """
    Holistic quality evaluation covering:
    - Content depth and originality
    - Technical analysis accuracy
    - Data source credibility
    - Writing clarity and structure
    - Timeliness and relevance
    """
    return {
        'overall_score': calculate_weighted_score(metrics),
        'dimension_scores': individual_metrics,
        'improvement_suggestions': generate_recommendations(metrics),
        'benchmarking': compare_to_peer_reports(report)
    }
```

## üîå External Integrations

### 1. Anthropic Claude Integration

Advanced language model integration for enhanced analysis:

```python
class ClaudeAPIClient:
    def __init__(self, api_key):
        self.client = anthropic.Client(api_key=api_key)
    
    def analyze_research_content(self, content, context=None):
        """
        Leverage Claude's advanced reasoning for:
        - Investment thesis validation
        - Risk assessment refinement
        - Market context integration
        - Recommendation quality enhancement
        """
        response = self.client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=2000,
            messages=[{
                "role": "user",
                "content": self.build_analysis_prompt(content, context)
            }]
        )
        return self.process_claude_response(response)
```

### 2. Yahoo Finance Integration

Real-time market data and financial metrics:

```python
def get_real_time_market_data(tickers):
    """
    Comprehensive market data retrieval:
    - Current stock prices and changes
    - Volume and trading statistics
    - Financial ratios and metrics
    - Historical performance data
    - Market sentiment indicators
    """
    market_data = {}
    for ticker in tickers:
        stock = yf.Ticker(ticker)
        market_data[ticker] = {
            'current_price': stock.info.get('currentPrice'),
            'day_change': stock.info.get('regularMarketChangePercent'),
            'volume': stock.info.get('volume'),
            'market_cap': stock.info.get('marketCap'),
            'pe_ratio': stock.info.get('trailingPE'),
            'dividend_yield': stock.info.get('dividendYield')
        }
    return market_data
```

### 3. Machine Learning Model Integration

Integration with pre-trained models for various AI tasks:

```python
class MLModelManager:
    def __init__(self):
        self.bert_model = self.load_bert_model()
        self.ai_detector = self.load_ai_detection_model()
        self.sentiment_analyzer = self.load_sentiment_model()
    
    def process_content(self, content):
        """
        Multi-model analysis pipeline:
        - BERT embeddings for semantic understanding
        - AI detection for content authenticity
        - Sentiment analysis for market bias detection
        - Named entity recognition for fact extraction
        """
        return {
            'semantic_embedding': self.bert_model.encode(content),
            'ai_probability': self.ai_detector.predict(content),
            'sentiment_score': self.sentiment_analyzer.analyze(content),
            'entities': self.extract_entities(content)
        }
```

## üß™ Testing

### Running Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test categories
python -m pytest tests/test_api.py -v           # API tests
python -m pytest tests/test_models.py -v       # Model tests
python -m pytest tests/test_ai_features.py -v  # AI functionality tests

# Run tests with coverage
python -m pytest tests/ --cov=app --cov-report=html
```

### Test Categories

#### 1. API Endpoint Tests (`tests/test_api.py`)

```python
def test_api_main_dashboard():
    """Test main dashboard API endpoint"""
    response = client.get('/api/main_dashboard')
    assert response.status_code == 200
    assert 'recent_reports' in response.json

def test_ai_research_assistant_api():
    """Test AI research assistant API"""
    response = client.post('/api/ai_research_assistant', 
                          json={'query': 'Latest on INFY stock'})
    assert response.status_code == 200
    assert response.json['success'] is True
```

#### 2. Model Tests (`tests/test_models.py`)

```python
def test_report_quality_scoring():
    """Test report quality assessment"""
    sample_report = create_sample_report()
    score = calculate_quality_score(sample_report.original_text)
    assert 0 <= score <= 100
    assert isinstance(score, float)

def test_plagiarism_detection():
    """Test plagiarism detection functionality"""
    text1 = "Sample investment analysis text"
    text2 = "Similar investment analysis content"
    similarity = detect_plagiarism(text1, text2)
    assert 0 <= similarity <= 1
```

#### 3. AI Feature Tests (`tests/test_ai_features.py`)

```python
def test_ai_content_detection():
    """Test AI-generated content detection"""
    ai_text = "This appears to be AI-generated content..."
    human_text = "This is clearly human-written analysis..."
    
    ai_score = detect_ai_content(ai_text)
    human_score = detect_ai_content(human_text)
    
    assert ai_score['ai_probability'] > human_score['ai_probability']
```

### Test Data Management

```python
# tests/conftest.py
@pytest.fixture
def sample_reports():
    """Generate sample reports for testing"""
    return [
        create_report("Analyst 1", "INFY.NS analysis", ["INFY.NS"]),
        create_report("Analyst 2", "TCS.NS research", ["TCS.NS"]),
        create_report("Analyst 3", "HDFC analysis", ["HDFCBANK.NS"])
    ]
```

## üìö Usage Examples

### 1. Basic Report Analysis

```python
# Submit a new report for analysis
import requests

report_data = {
    'analyst': 'John Doe',
    'report_text': 'Detailed investment analysis of INFY.NS...',
    'tickers': ['INFY.NS']
}

response = requests.post('http://localhost:5008/analyze', 
                        json=report_data)
result = response.json()

print(f"Quality Score: {result['quality_score']}")
print(f"AI Detection: {result['ai_probability']}")
print(f"Extracted Tickers: {result['tickers']}")
```

### 2. AI Research Assistant Query

```python
# Query the AI research assistant
query_data = {
    'query': 'What are the latest trends in the Indian IT sector?',
    'investor_id': 'optional_investor_id'
}

response = requests.post('http://localhost:5008/api/ai_research_assistant',
                        json=query_data)
result = response.json()

print(f"AI Response: {result['ai_response']}")
print(f"Confidence: {result['confidence_score']}")
```

### 3. Real-time Market Data

```python
# Get live market metrics
response = requests.get('http://localhost:5008/api/metrics')
metrics = response.json()

print(f"Total Reports: {metrics['total_reports']}")
print(f"Active Analysts: {metrics['active_analysts']}")
print(f"Market Status: {metrics['market_status']}")
```

### 4. Agentic AI Recommendations

```python
# Get AI agent investment recommendations
response = requests.get('http://localhost:5008/api/agentic/recommendations')
recommendations = response.json()

for rec in recommendations['data']:
    print(f"Ticker: {rec['ticker']}")
    print(f"Recommendation: {rec['recommendation_type']}")
    print(f"Confidence: {rec['confidence_score']}")
    print(f"Target Price: {rec['target_price']}")
    print(f"Reasoning: {rec['reasoning']}")
    print("---")
```

## ü§ñ Agentic AI System

The application includes a sophisticated autonomous AI system for investment management.

### Agent Architecture

```python
class InvestmentAgent:
    """
    Autonomous investment agent with capabilities:
    - Portfolio monitoring and optimization
    - Market analysis and trend detection
    - Risk assessment and management
    - Automated recommendation generation
    """
    
    def __init__(self, investor_profile):
        self.profile = investor_profile
        self.risk_tolerance = investor_profile['risk_tolerance']
        self.investment_goals = investor_profile['goals']
        self.performance_history = []
    
    def analyze_portfolio(self):
        """Comprehensive portfolio analysis"""
        return {
            'current_allocation': self.get_current_allocation(),
            'risk_metrics': self.calculate_risk_metrics(),
            'performance_attribution': self.analyze_performance(),
            'rebalancing_recommendations': self.generate_rebalancing_advice()
        }
    
    def generate_recommendations(self):
        """AI-powered investment recommendations"""
        market_data = self.get_market_context()
        portfolio_analysis = self.analyze_portfolio()
        
        return self.ml_recommendation_engine.generate_recommendations(
            portfolio_analysis, market_data, self.profile
        )
```

### Agent Capabilities

#### 1. Portfolio Monitoring
- Real-time portfolio value tracking
- Performance attribution analysis
- Risk metric calculation
- Benchmark comparison

#### 2. Market Analysis
- Technical indicator analysis
- Fundamental data processing
- Sentiment analysis integration
- Economic indicator correlation

#### 3. Risk Management
- Value-at-Risk (VaR) calculation
- Stress testing scenarios
- Correlation analysis
- Concentration risk assessment

#### 4. Recommendation Engine
- Machine learning-based stock selection
- Portfolio optimization algorithms
- Timing recommendation systems
- Risk-adjusted return optimization

## üõ°Ô∏è Security Features

### 1. Authentication & Authorization

```python
@app.before_request
def check_authentication():
    """
    Multi-layer security implementation:
    - Session-based authentication
    - Role-based access control (RBAC)
    - API key validation for external access
    - Rate limiting and abuse prevention
    """
    if request.endpoint in protected_endpoints:
        if not session.get('user_id'):
            return redirect(url_for('login'))
        
        if not check_user_permissions(session['user_id'], request.endpoint):
            abort(403)
```

### 2. Data Protection

- **Input Sanitization**: All user inputs are sanitized and validated
- **SQL Injection Prevention**: SQLAlchemy ORM with parameterized queries
- **XSS Protection**: Jinja2 template auto-escaping enabled
- **CSRF Protection**: Flask-WTF CSRF tokens for forms

### 3. API Security

```python
def rate_limit_check(request):
    """
    API rate limiting implementation:
    - Per-user request limits
    - Endpoint-specific throttling
    - Burst protection mechanisms
    - Distributed rate limiting support
    """
    user_id = get_user_id_from_request(request)
    endpoint = request.endpoint
    
    if exceed_rate_limit(user_id, endpoint):
        abort(429, "Rate limit exceeded")
```

### 4. Data Encryption

- **Database Encryption**: Sensitive fields encrypted at rest
- **API Key Protection**: Environment variable storage
- **Session Security**: Secure session cookie configuration
- **Transport Security**: HTTPS enforcement in production

## üìà Performance & Monitoring

### 1. Performance Metrics

The application tracks comprehensive performance metrics:

```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'query_performance': {},
            'ai_model_latency': [],
            'database_performance': {},
            'memory_usage': [],
            'cpu_utilization': []
        }
    
    def log_request_performance(self, endpoint, duration):
        """Track API endpoint performance"""
        self.metrics['response_times'].append({
            'endpoint': endpoint,
            'duration': duration,
            'timestamp': datetime.utcnow()
        })
    
    def analyze_performance_trends(self):
        """Generate performance analysis report"""
        return {
            'avg_response_time': self.calculate_average_response_time(),
            'slowest_endpoints': self.identify_slow_endpoints(),
            'peak_usage_times': self.analyze_usage_patterns(),
            'resource_bottlenecks': self.identify_bottlenecks()
        }
```

### 2. Logging Configuration

```python
import logging
from logging.handlers import RotatingFileHandler

# Configure comprehensive logging
if not app.debug:
    file_handler = RotatingFileHandler('logs/app.log', 
                                     maxBytes=10240, backupCount=10)
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
    ))
    file_handler.setLevel(logging.INFO)
    app.logger.addHandler(file_handler)
    app.logger.setLevel(logging.INFO)
    app.logger.info('Application startup')
```

### 3. Health Monitoring

```python
@app.route('/health')
def health_check():
    """
    Comprehensive health check endpoint:
    - Database connectivity
    - External API availability
    - AI model status
    - System resource usage
    """
    health_status = {
        'database': check_database_health(),
        'external_apis': check_external_api_health(),
        'ai_models': check_ai_model_health(),
        'system_resources': get_system_resource_status(),
        'timestamp': datetime.utcnow().isoformat()
    }
    
    overall_status = all(health_status[key]['status'] == 'healthy' 
                        for key in health_status if key != 'timestamp')
    
    return jsonify({
        'status': 'healthy' if overall_status else 'degraded',
        'details': health_status
    }), 200 if overall_status else 503
```

## üöÄ Deployment

### Production Deployment with Docker

#### 1. Create Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 5008

# Use Gunicorn for production
CMD ["gunicorn", "--bind", "0.0.0.0:5008", "--workers", "4", "app:app"]
```

#### 2. Docker Compose Configuration

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "5008:5008"
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=postgresql://user:pass@db:5432/research_db
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./logs:/app/logs
  
  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=research_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:6
    ports:
      - "6379:6379"
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app

volumes:
  postgres_data:
```

### Production Configuration

#### 1. Environment Variables

```bash
# Production environment file (.env.prod)
FLASK_ENV=production
DEBUG=False
SECRET_KEY=your-production-secret-key

# Database
DATABASE_URL=postgresql://username:password@localhost/production_db

# External APIs
ANTHROPIC_API_KEY=your-production-claude-key
YAHOO_FINANCE_API_KEY=your-yahoo-finance-key

# Security
SSL_REDIRECT=True
SECURE_COOKIE=True

# Performance
WORKERS=4
MAX_CONNECTIONS=1000
TIMEOUT=120

# Monitoring
LOG_LEVEL=INFO
SENTRY_DSN=your-sentry-dsn
```

#### 2. Nginx Configuration

```nginx
upstream research_app {
    server app:5008;
}

server {
    listen 80;
    server_name yourdomain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name yourdomain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    client_max_body_size 50M;

    location / {
        proxy_pass http://research_app;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /static {
        alias /app/static;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

### Monitoring and Maintenance

#### 1. System Monitoring

```python
# scripts/system_monitor.py
import psutil
import requests
from datetime import datetime

def monitor_system_health():
    """Comprehensive system monitoring"""
    metrics = {
        'timestamp': datetime.utcnow(),
        'cpu_percent': psutil.cpu_percent(interval=1),
        'memory_percent': psutil.virtual_memory().percent,
        'disk_usage': psutil.disk_usage('/').percent,
        'network_io': psutil.net_io_counters()._asdict(),
        'process_count': len(psutil.pids())
    }
    
    # Check application health
    try:
        response = requests.get('http://localhost:5008/health', timeout=5)
        metrics['app_health'] = response.status_code == 200
    except:
        metrics['app_health'] = False
    
    return metrics
```

#### 2. Automated Backups

```bash
#!/bin/bash
# scripts/backup_database.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups"
DB_NAME="research_db"

# Create database backup
pg_dump -h localhost -U username $DB_NAME > $BACKUP_DIR/db_backup_$DATE.sql

# Compress backup
gzip $BACKUP_DIR/db_backup_$DATE.sql

# Remove backups older than 30 days
find $BACKUP_DIR -name "db_backup_*.sql.gz" -mtime +30 -delete

echo "Database backup completed: db_backup_$DATE.sql.gz"
```

## ü§ù Contributing

### Development Workflow

1. **Fork and Clone**
   ```bash
   git clone https://github.com/your-username/research-quality-app.git
   cd research-quality-app
   ```

2. **Create Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Install Development Dependencies**
   ```bash
   pip install -r requirements-dev.txt
   pre-commit install
   ```

4. **Make Changes and Test**
   ```bash
   # Run tests
   python -m pytest tests/ -v
   
   # Check code style
   flake8 app.py
   black app.py --check
   
   # Type checking
   mypy app.py
   ```

5. **Submit Pull Request**

### Code Style Guidelines

- **Python**: Follow PEP 8, use Black for formatting
- **JavaScript**: Use ESLint with standard configuration
- **Documentation**: Update README and docstrings for new features
- **Testing**: Maintain >90% test coverage for new code

### Issue Reporting

When reporting issues, please include:
- Python version and operating system
- Complete error traceback
- Steps to reproduce the issue
- Expected vs actual behavior
- Relevant configuration details

## üìÑ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## üìû Support & Contact

For questions, issues, or contributions:

- **Documentation**: Check this README and `/docs` folder
- **Issues**: Use GitHub Issues for bug reports and feature requests
- **Discussions**: Use GitHub Discussions for questions and ideas

---

**Built with ‚ù§Ô∏è for the investment research community**

*This application represents a comprehensive solution for modern investment research analysis, combining traditional financial analysis with cutting-edge AI technologies to deliver superior insights and decision-making capabilities.*

- Machine learning model improvements
- Additional compliance frameworks
- Enhanced visualization capabilities
- Mobile application support
- Advanced portfolio optimization tools

## ü§ù Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üìû Support

For support and questions:
- Create an issue in the repository
- Contact the development team
- Check the documentation wiki

---

**Version**: 2.4.1.2
**Last Updated**: 2024
**Platform**: Web-based Flask Application
**Database**: SQLite/PostgreSQL Compatible